# Introduction

# Use case

1. Use spark inside ipython notebook
2. Write parallel code to handle big data easily in spark. So much paintful when you run that in python using multiple process or thread.
3. Connect the other machines in your laboratory as workers and form a powerful computing just in one seconds

# TODO:

* Improving documents